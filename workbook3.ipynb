{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MA934 Numerical Methods - Workbook 3\n",
    "\n",
    "If you haven't already done so, install the DualNumbers Julia package. It is a good idea to update all your packages first. The commands are\n",
    "\n",
    ">Pkg.update()\n",
    "\n",
    ">Pkg.add(\"DualNumbers\")\n",
    "\n",
    "but you only need to run them once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mINFO: Precompiling module DualNumbers.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "using Plots\n",
    "using DualNumbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Numerical differentiation\n",
    "\n",
    "**1))** Derive a finite difference formula for the derivative of a function, $f$ at a point $x$ using the 3-point stencil $(x, x+h, x+2h)$ and state the order of the approximation error in terms of $h$.\n",
    "\n",
    "**2)** Write a formula for the derivative, $f^\\prime(x)$, of the function\n",
    "\n",
    "$$f(x) = \\sin(\\exp(x)) $$\n",
    "\n",
    "and evaluate it at $x=1$.\n",
    "\n",
    "**3)** Use your finite difference formula to approximate the value of $f^\\prime(1)$ for values of $h$ decreasing from $2^{-1}$ to $2^{-30}$ in powers of $2$. Plot the error as a function of $h$ and verify the theoretically predicted scaling of the error with $h$. What is the best relative error you can achieve?\n",
    "\n",
    "**4)** Read the examples at https://github.com/JuliaDiff/DualNumbers.jl. Define a dual number $x = 1+\\epsilon$ and use it to evaluate $f^\\prime(1)$. Verify that the answer is accurate to within machine precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition f(Any) in module Main at In[3]:2 overwritten at In[4]:2.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8 + 12É›"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Dual(2,1)\n",
    "f(x) = x^3\n",
    "\n",
    "y = f(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Finding roots\n",
    "\n",
    "**1)** Referring to the function, $f(x)$, defined above, find the roots of the equation\n",
    "\n",
    "$$ f(x) = 0$$\n",
    "\n",
    "in the interval $0<x<2$.\n",
    "\n",
    "**2)** Implement the bracketing and bisection method to find one of the roots numerically. Measure the error at each iteration of the algorithm and demonstrate that the error decreases exponentially as a function of the number of iterations. To how many digits of precision can you approximate the root?\n",
    "\n",
    "**3)** Perform the same measurements for the Newton Raphson method and show that the error decreases faster than exponentially as a function of the number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Finding minima\n",
    "\n",
    "**1)** The function $f(x)$ above has a single minimum in the interval $0<x<2$. Find its location analytically.\n",
    "\n",
    "**2)** Implement the Golden section search to find the location of this minimum numerically. Plot the error as a function of the number of iterations. To how many digits of precision can you approximate the location of the minimum?\n",
    "\n",
    "**3)** To understand your empirical findings, use Taylor's Theorem to show that near a minimum, $x_*$, of f(x),\n",
    "\n",
    "$$f(x) \\approx f(x_*)\\left( 1+ \\frac{f^{\\prime\\prime}(x_*)}{2\\,f(x_*)}\\,(x-x_*)^2\\right). $$\n",
    "Show that in order for a computer to distinguish between $f(x)$ and $f(x_*)$ we must have\n",
    "\n",
    "$$ \\left| x-x_*\\right| > \\sqrt{\\epsilon_m}\\,\\sqrt{\\left|\\frac{2\\,f(x_*)}{f^{\\prime\\prime}(x_*)}\\right|}$$\n",
    "\n",
    "thus limiting the precision with which the location of a minimum can be determined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.2",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
